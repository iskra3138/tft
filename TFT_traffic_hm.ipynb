{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFT_traffic",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true,
	  "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskra3138/tft/blob/master/TFT_traffic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alNUrjp9_oQr",
        "colab_type": "text"
      },
      "source": [
        "Ref.\n",
        "- https://github.com/google-research/google-research/blob/master/tft/script_train_fixed_params.py\n",
        "- https://aihub.cloud.google.com/u/0/p/products%2F9f39ad8d-ad81-4fd9-8238-5186d36db2ec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl5UrzdzYULE",
        "colab_type": "code",
        "outputId": "00eda29c-5234-4685-fea4-31ebb7ed2cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun  4 04:56:56 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0H5nv-wbdiT",
        "colab_type": "code",
        "outputId": "ec52e85b-f16e-4f0e-fdcf-46ddbc49d47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "source": [
        "# install packages to download data and restart runtime\n",
        "!pip install pyunpack\n",
        "!pip install wget"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyunpack\n",
            "  Downloading https://files.pythonhosted.org/packages/33/fd/4b64817a1d82df78553ceb1bfc5a2d7ac162da8667be586430fab9db5deb/pyunpack-0.2.1-py2.py3-none-any.whl\n",
            "Collecting entrypoint2\n",
            "  Downloading https://files.pythonhosted.org/packages/46/0a/6156f1bc14a44094cff75bb6ecefe1f8e8a12cfff66379ba3d52d0916c49/entrypoint2-0.2.1-py2.py3-none-any.whl\n",
            "Collecting easyprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Installing collected packages: argparse, entrypoint2, easyprocess, pyunpack\n",
            "Successfully installed argparse-1.4.0 easyprocess-0.3 entrypoint2-0.2.1 pyunpack-0.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=3f37ea8f0a1ad5ef2847347ab191f00c964de116145f760416eed122e70ec899\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp2Bc9Vzp9qm",
        "colab_type": "text"
      },
      "source": [
        "if the code is in goole drive, the following cell doesn't need to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98IFojfBaDYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install to download only tft directory \n",
        "#!pip install git+git://github.com/HR/github-clone#egg=ghclone\n",
        "#!ghclone https://github.com/google-research/google-research/tree/master/tft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cJGTf7Ye1Kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg9sns1xe4KR",
        "colab_type": "code",
        "outputId": "742e90db-e285-4be2-db39-5d7160d2aeec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "drive.mount('/Gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /Gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoRHuON8fDvO",
        "colab_type": "code",
        "outputId": "84474110-40da-4eaa-81e6-04de65b11936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd '/Gdrive/My Drive/TFT'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Gdrive/My Drive/TFT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBWNXwCra17l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ghclone https://github.com/google-research/google-research/tree/master/tft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsv0JsDXdhZD",
        "colab_type": "code",
        "outputId": "5b0ba7ad-1f1a-4484-ffde-5b06fee21232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVjQoBZrbBig",
        "colab_type": "code",
        "outputId": "7919459b-56d1-4f0f-e546-af050dfd4a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd tft"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Gdrive/My Drive/TFT/tft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU8gftpOcRbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# where $EXPT can be any of {volatility, electricity, traffic, favorita}, \n",
        "# and $OUTPUT_FOLDER denotes the root folder in which experiment outputs are saved.\n",
        "EXPT='traffic'\n",
        "OUTPUT_FOLDER='traffic_test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJaqRgtEbJR-",
        "colab_type": "code",
        "outputId": "06374a6b-c7e2-49a7-b2aa-0075ddfc3fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "# download $EXPT data\n",
        "!python3 -m script_download_data $EXPT $OUTPUT_FOLDER"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#### Running download script ###\n",
            "Resetting data folder...\n",
            "Getting traffic data...\n",
            "Pulling data from https://archive.ics.uci.edu/ml/machine-learning-databases/00204/PEMS-SF.zip to traffic_test/data/traffic/PEMS-SF.zip\n",
            "done\n",
            "Unzipping file: traffic_test/data/traffic/PEMS-SF.zip\n",
            "Done.\n",
            "Aggregating to hourly data\n",
            "Completed 50 of 267 rows for PEMS_train\n",
            "Completed 100 of 267 rows for PEMS_train\n",
            "Completed 150 of 267 rows for PEMS_train\n",
            "Completed 200 of 267 rows for PEMS_train\n",
            "Completed 250 of 267 rows for PEMS_train\n",
            "Completed 50 of 173 rows for PEMS_test\n",
            "Completed 100 of 173 rows for PEMS_test\n",
            "Completed 150 of 173 rows for PEMS_test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnWfzi9ZxsT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import datetime as dte\n",
        "import os\n",
        "\n",
        "import data_formatters.base\n",
        "import expt_settings.configs\n",
        "import libs.hyperparam_opt\n",
        "import libs.tft_model\n",
        "import libs.utils as utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.compat.v1 as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1IVWsZ9DP9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ExperimentConfig = expt_settings.configs.ExperimentConfig\n",
        "HyperparamOptManager = libs.hyperparam_opt.HyperparamOptManager\n",
        "ModelClass = libs.tft_model.TemporalFusionTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj5648AdC6a_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# args for electricity testing from gpu\n",
        "name, output_folder, use_tensorflow_with_gpu = EXPT, OUTPUT_FOLDER, True\n",
        "\n",
        "print(\"Using output folder {}\".format(output_folder))\n",
        "\n",
        "config = ExperimentConfig(name, output_folder)\n",
        "formatter = config.make_data_formatter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9AOxFplDMvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "expt_name=name\n",
        "use_gpu=use_tensorflow_with_gpu\n",
        "model_folder=os.path.join(config.model_folder, \"fixed\")\n",
        "data_csv_path=config.data_csv_path\n",
        "data_formatter=formatter\n",
        "#use_testing_mode=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-kRrsjNDTcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#num_repeats = 1\n",
        "\n",
        "if not isinstance(data_formatter, data_formatters.base.GenericDataFormatter):\n",
        "  raise ValueError(\n",
        "      \"Data formatters should inherit from\" +\n",
        "      \"AbstractDataFormatter! Type={}\".format(type(data_formatter)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9VZp6v3DWhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensorflow setup\n",
        "default_keras_session = tf.keras.backend.get_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnmReq6XDrbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if use_gpu:\n",
        "  tf_config = utils.get_default_tensorflow_config(tf_device=\"gpu\", gpu_id=0)\n",
        "\n",
        "else:\n",
        "  tf_config = utils.get_default_tensorflow_config(tf_device=\"cpu\")\n",
        "\n",
        "print(\"*** Training from defined parameters for {} ***\".format(expt_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fJq9WX7h3g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSBD3lIcDupO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Loading & splitting data...\")\n",
        "raw_data = pd.read_csv(data_csv_path, index_col=0)\n",
        "train, valid, test = data_formatter.split_data(raw_data)\n",
        "train_samples, valid_samples = data_formatter.get_num_samples_for_calibration(\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyqTAyzvEPKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sets up default params\n",
        "fixed_params = data_formatter.get_experiment_params()\n",
        "params = data_formatter.get_default_model_params()\n",
        "params[\"model_folder\"] = model_folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpaKzLKSER0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sets up hyperparam manager\n",
        "print(\"*** Loading hyperparm manager ***\")\n",
        "opt_manager = HyperparamOptManager({k: [params[k]] for k in params},\n",
        "                                    fixed_params, model_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi6MhjZgEWJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training -- one iteration only\n",
        "print(\"*** Running calibration ***\")\n",
        "print(\"Params Selected:\")\n",
        "for k in params:\n",
        "  print(\"{}: {}\".format(k, params[k]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSQcTBsUyqVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = opt_manager.get_next_parameters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GgSarbS-_5S",
        "colab_type": "text"
      },
      "source": [
        "Next, we train a TFT model by subsampling the data in the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef7yKO3OxOV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Graph().as_default(), tf.Session(config=tf_config) as sess:\n",
        "\n",
        "    tf.keras.backend.set_session(sess)\n",
        "    \n",
        "    # Create a TFT model\n",
        "    model = ModelClass(params, use_cudnn=True) # Run model on GPU using CuDNNLSTM cells\n",
        "\n",
        "    # Sample data into minibatches for training\n",
        "    if not model.training_data_cached():\n",
        "        model.cache_batched_data(train, \"train\", num_samples=450000)\n",
        "        model.cache_batched_data(valid, \"valid\", num_samples=50000)\n",
        "\n",
        "    # Train and save model\n",
        "    model.fit()\n",
        "    model.save(model_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G5DYRv8-4F0",
        "colab_type": "text"
      },
      "source": [
        "To evaluate model performance, we reload the serialised model and compute P50 and P90 losses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af9YuQLkxOQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Graph().as_default(), tf.Session(config=tf_config) as sess:\n",
        "\n",
        "    tf.keras.backend.set_session(sess)\n",
        "    \n",
        "    # Create a new model & load weights\n",
        "    model = ModelClass(params, use_cudnn=True)\n",
        "    model.load(model_folder)\n",
        "    \n",
        "    # Make forecasts\n",
        "    output_map = model.predict(test, return_targets=True)\n",
        "\n",
        "    targets = data_formatter.format_predictions(output_map[\"targets\"])\n",
        "\n",
        "    # Format predictions\n",
        "    p50_forecast = data_formatter.format_predictions(output_map[\"p50\"])\n",
        "    p90_forecast = data_formatter.format_predictions(output_map[\"p90\"])\n",
        "\n",
        "    def extract_numerical_data(data):\n",
        "        \"\"\"Strips out forecast time and identifier columns.\"\"\"\n",
        "        return data[[\n",
        "          col for col in data.columns\n",
        "          if col not in {\"forecast_time\", \"identifier\"}\n",
        "        ]]\n",
        "\n",
        "    # Compute Losses\n",
        "    p50_loss = utils.numpy_normalised_quantile_loss(\n",
        "        extract_numerical_data(targets), extract_numerical_data(p50_forecast),\n",
        "        0.5)\n",
        "    p90_loss = utils.numpy_normalised_quantile_loss(\n",
        "        extract_numerical_data(targets), extract_numerical_data(p90_forecast),\n",
        "        0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rWuh9RjilD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Normalised quantile losses: P50={}, P90={}\".format(p50_loss.mean(), p90_loss.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwCE4Fzk-f-d",
        "colab_type": "text"
      },
      "source": [
        "## Interpretability Use Cases\n",
        "The relationships learnt by the TFT can also be studied using the trained model, through:\n",
        "\n",
        "1. Analyzing the variable selection weights to identify significant features for the prediction problem.\n",
        "2. Visualizing distributions of self-attention weights to determine the presence of any persistent temporal relationships.\n",
        "\n",
        "In the remainder of this section, we demonstrate two interpretability use cases to showcase the above.\n",
        "\n",
        "### Generate Weights for Interpretability\n",
        "First, we generate all necessary variable selection and attention weights required for analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1BekVSnilBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store outputs in maps\n",
        "counts = 0\n",
        "interpretability_weights = {k: None for k in ['decoder_self_attn', \n",
        "                                              'static_flags', 'historical_flags', 'future_flags']}\n",
        "\n",
        "tf.reset_default_graph()\n",
        "with tf.Graph().as_default(), tf.Session(config=tf_config) as sess:\n",
        "\n",
        "    tf.keras.backend.set_session(sess)\n",
        "    \n",
        "    # Create a new model & load weights\n",
        "    model = ModelClass(params, \n",
        "                                    use_cudnn=True)\n",
        "    model.load(model_folder)\n",
        "    for identifier, sliced in test.groupby('id'):\n",
        "        \n",
        "        print(\"Getting attention weights for {}\".format(identifier))\n",
        "        weights = model.get_attention(sliced)\n",
        "        \n",
        "        for k in interpretability_weights:\n",
        "            w = weights[k]\n",
        "            \n",
        "            # Average attentin across heads if necessary\n",
        "            if k == 'decoder_self_attn':\n",
        "                w = w.mean(axis=0)\n",
        "            \n",
        "                # Store a single matrix for weights to reduce memory footprint\n",
        "                batch_size, _, _ = w.shape                 \n",
        "                counts += batch_size\n",
        "            \n",
        "            if interpretability_weights[k] is None:\n",
        "                interpretability_weights[k] = w.sum(axis=0)\n",
        "            else:\n",
        "                interpretability_weights[k] += w.sum(axis=0)\n",
        "\n",
        "interpretability_weight = {k: interpretability_weights[k]/counts for k in interpretability_weights}\n",
        "\n",
        "print('Done.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEZQ_lqdik9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj2XFC0ilQIZ",
        "colab_type": "text"
      },
      "source": [
        "### Use Case 1: Analyzing Variable Importance \n",
        "\n",
        "Next, we analyze the distribution of variable selection weights on the input layer -- using this to quantify the relative importance of a given feature for the prediction problem in general. This is split into variable importance for static covariates, time-varying historical inputs variables and known future inputs as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ive5gh7wlGz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def get_range(static_gate, axis=None):\n",
        "    \"\"\"Returns the mean, 10th, 50th and 90th percentile of variable importance weights.\"\"\"\n",
        "    return {'Mean': static_gate.mean(axis=axis), \n",
        "               '10%': np.quantile(static_gate, 0.1, axis=axis),\n",
        "               '50%': np.quantile(static_gate, 0.5, axis=axis),\n",
        "               '90%': np.quantile(static_gate, 0.9, axis=axis)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrJS_qSNlTb7",
        "colab_type": "text"
      },
      "source": [
        "#### Static Variable Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6qIdonllGxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten(x):\n",
        "    static_attn = x\n",
        "    static_attn = static_attn.reshape([-1, static_attn.shape[-1]])\n",
        "    return static_attn\n",
        "\n",
        "static_attn = flatten(interpretability_weights['static_flags'])\n",
        "m = get_range(static_attn, axis=0)\n",
        "pd.DataFrame({k: pd.Series(m[k], index=['ID']) for k in m})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzaaTKE8lY9E",
        "colab_type": "text"
      },
      "source": [
        "#### Temporal Variable Importance -- Past Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oha90VbqlGqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = flatten(interpretability_weights['historical_flags'])\n",
        "m = get_range(x, axis=0)\n",
        "pd.DataFrame({k: pd.Series(m[k], index=['Hour of Day', 'Day of Week', 'Time Index', 'Target']) for k in m})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL1gsML3lcvu",
        "colab_type": "text"
      },
      "source": [
        "#### Temporal Variable Importance -- Future Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4NjMQ13lGme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = flatten(interpretability_weights['future_flags'])\n",
        "m = get_range(x, axis=0)\n",
        "pd.DataFrame({k: pd.Series(m[k], index=['Hour of Day', 'Day of Week', 'Time Index']) for k in m})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtaf1xHeljhO",
        "colab_type": "text"
      },
      "source": [
        "### Use Case 2: Visualizing Persistent Temporal Patterns\n",
        "Lastly, we analyse the distribution of self-attention weights across various horizons to see if any persistent temporal patterns exist within the dataset. This allows us to identify any seasonal patterns or lagged relationships in the dataset, based on which past time steps are consistently important for predictions at a given horizon. \n",
        "\n",
        "We visualize this using the average attention pattern for various prediction horizons, as shown below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVf3_VLVlmWQ",
        "colab_type": "text"
      },
      "source": [
        "#### Mean Attention Weights for Various Prediction Horizons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mRSUbPXlGkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting libraries & Functions\n",
        "import plotly.offline\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot\n",
        "import plotly.graph_objs as go\n",
        "import cufflinks as cf\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Loads plotly charts\n",
        "def iplot(fig, s='plot.html'):\n",
        "    filename = os.path.join(output_folder, s)\n",
        "    plotly.offline.plot(fig, filename=filename, auto_open=False)\n",
        "    return HTML(filename)    \n",
        "\n",
        "def plotly_chart(df, title=None, kind='scatter', x_label=None, y_label=None, secondary_y=None, fill=None,\n",
        "                shape=None, subplots=False):\n",
        "    \n",
        "    fig = df.iplot(asFigure=True, title=title, kind=kind, xTitle=x_label, yTitle=y_label, secondary_y=secondary_y,\n",
        "                  fill=fill, subplots=subplots, shape=shape)\n",
        "\n",
        "    return iplot(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU1sb69SlGiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "self_attn = interpretability_weights['decoder_self_attn']\n",
        "\n",
        "means = pd.DataFrame({\"horizon={}\".format(k): self_attn[model.num_encoder_steps+k-1, :] \n",
        "                      for k in [1, 5, 10, 15, 20]})\n",
        "means.index -= model.num_encoder_steps\n",
        "\n",
        "plotly_chart(means,\n",
        "             x_label=\"Positiion Index (n)\",\n",
        "             y_label=\"Mean Attention Weight\",\n",
        "             title=\"Average Attention Pattern at Various Prediction Horizons\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnbQueJmNgy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}